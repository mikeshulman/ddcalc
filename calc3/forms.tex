\documentclass[12pt]{amsart}
\usepackage{fullpage}
\input{../macros}
\title{On differential forms}
\begin{document}
\maketitle

In your previous calculus classes, you may or may not have encountered \emph{differential forms} by name.
However, you've certainly met them, even if you didn't realize it.
When you write
\[ \int_{x=a}^b f(x) \,\dx \]
the thing being integrated, ``$f(x) \,\dx$'', is a differential form.

You may have been told that the ``$\dx$'' is simply a notation that indicates which variable we're integrating, but this is a lie.
In multivariable calculus, we can no longer maintain this fiction: we have to treat differential forms as honest objects.
Fortunately, we also have two advantages over one-variable calculus in understanding differential forms: we have \emph{vectors} at our disposal; and some things are actually \emph{less} confusing in more dimensions because there are fewer coincidences to get confused by.

\section{Differential forms}
\label{sec:differential-forms}

If $\dx$ isn't just a notation indicating the integration variable, what is it?
If you encountered differentials in one-variable calculus, you may have been told that $\dx$ is a small change in $x$ (sometimes denoted $\Delta x$), or even an ``infinitesimal'' change in $x$.
These are not wrong, but with vectors we can give a better definition.

\begin{defn}
  A \textbf{differential 1-form} is a function whose input is a point $\pt{x}$ \emph{and} a vector based at $\pt{x}$.
  We denote the vector by $\dpx$.
\end{defn}

In $n$ dimensions, the point $\pt{x}$ has $n$ coordinates, as does the vector $\dpx$.
As usual, in 2 or 3 dimensions we denote the coordinates of $\pt{x}$ by $\ptc{x,y}$ or $\ptc{x,y,z}$.
Similarly, we denote the coordinates of $\dpx$ by $\vcc{\dx,\dy}$ or $\vcc{\dx,\dy,\dz}$.
We can then describe a differential form by a formula involving these coordinates $x,y,z,\dx,\dy,\dz$.

\begin{egs}
  The following are all differential 1-forms:
  \begin{gather*}
    x^2 \,\dx + 2xy \, \dy\\
    \half({x-z}) \,\dx - 4\, \dy + e^y \,\dz\\
    1 + \dx + \half \dx^2 + \third \dx^3\\
    \sin(x + \dx) - \sin(x)\\
    \sqrt{\dx^2+\dy^2}
  \end{gather*}
\end{egs}

Note that although $\dx$ is two letters, we regard it as one symbol standing for one variable.
In particular, an expression such as $\dx^2$ means $(\dx)^2$, not $\dd(x^2)$.
(We will give a different meaning to $\dd(x^2)$ in \cref{sec:differentials}.)

Of these examples, the first two are special in the following way.

\begin{defn}
  A \textbf{linear} differential 1-form is one defined by an expression of the form
  \[ f(\pt{x}) \, \dx + g(\pt{x}) \, \dy + h(\pt{x}) \, \dz. \]
  Here $f$, $g$, and $h$ are functions of the point $\pt{x}$ only, and each of them is multiplied by one of the coordinates of $\dpx$.
\end{defn}

Most mathematicians only use the term ``differential 1-form'' for linear ones.
However, the more general ones are quite useful.

It is helpful to think of the coordinates $\dx$, $\dy$, and $\dz$ as small changes in the value of $x$.
For instance, if $x=3$, then a possible small change would be $\dx = 0.01$.
In this case, a differential form such as $\dx^2$ is an \emph{even smaller} change, since $\dx^2 = 0.0001$.
We say that $\dx$ is a \emph{first-order} form while $\dx^2$ is \emph{second-order}.

The concept of order can be applied even to forms that are not polynomials in $\dx$.
For instance, if $\dx=0.01$, then $\sin \dx \approx 0.0099998$, which is about the same size as $\dx$.
Thus, it is reasonable to say that $\sin\dx$ is also first-order.
On the other hand, still with $\dx=0.01$, we have $\cos \dx - 1 \approx -0.00005$, which is much smaller than $\dx$ and about the same size as $\dx^2$.
Thus, it is reasonable to say that $\cos \dx - 1$ is second-order.

We make this idea precise with the following definition.

\begin{defn}
  Let $n$ be an integer $\ge 0$.
  A 1-form $\omega$ is \textbf{$n\th$ order} at a point $\pt{x}$ if
  \[ \lim_{h\to 0} \frac{\omega(\pt{x},h\,\dd\pt{x})}{h^{n-1}} = 0 \]
  for all vectors $\dpx$ based at $\pt{x}$.
\end{defn}

\begin{eg}
  A continuous \emph{linear} differential 1-form is first order at every point.
  For instance, if $\omega(\pt{x},\dd\pt{x}) = f(\pt{x}) \, \dx$, then
  \[ \frac{\omega(\pt{x},h\,\dd\pt{x})}{h^0} = f(\pt{x}) \, h\, \dx,\]
  which goes to zero as $h\to 0$ (for fixed $\pt{x}$ and $\dd\pt{x}$).
\end{eg}

\begin{eg}
  Any continuous differential 1-form is zeroth order at every point.
  For since $\frac{1}{h^{-1}} = h$, we have
  \[\frac{\omega(\pt{x},h\,\dpx)}{h^{-1}} = h \,\omega(\pt{x},h\,\dpx).\]
  Since $\omega$ is continuous, $\lim_{h\to 0} \omega(\pt{x},h\,\dpx)$ exists; while of course $\lim_{h\to 0} h = 0$.
  Thus, by the product law for limits, the limit of the product is also zero.
\end{eg}

\begin{eg}
  The differential form $\dx^2$ is second order at any point.
  We have
  \[ \frac{\omega(\pt{x},h\,\dd\pt{x})}{h^1} = \frac{(h\,\dx)^2}{h} = \frac{h^2 \, \dx^2}{h} = h \,\dx^2 \]
  which goes to zero as $h\to 0$.
\end{eg}

\begin{eg}
  The differential form $\sqrt{\dx^2+\dy^2}$ is first order at any point.
  We have
  \[ \frac{\sqrt{(h\,\dx)^2+(h\,\dy)^2}}{h^0} =
  \sqrt{h^2\,\dx^2+h^2\,\dy^2} = |h| \, \sqrt{\dx^2+\dy^2}
  \]
  which goes to zero as $h\to 0$.
\end{eg}

We also have the following rules for orders of forms.
These can be proven from the limit laws from one-variable calculus.

\begin{thm}
  Let $\omega$ and $\eta$ be differential 1-forms, and assume that $\omega$ is $n\th$ order and $\eta$ is $m\th$ order at $\pt{x}$.
  \begin{enumerate}
  \item $\omega+\eta$ is $\min(n,m)\th$ order at $\pt{x}$.
  \item $\omega\eta$ is $(n+m)\th$ order at $\pt{x}$.
  \end{enumerate}
\end{thm}

It follows that a polynomial in the differential variables $\dx,\dy,\dz$ has the order of the lowest total degree of these variables in all of its terms.
Thus, $x^3\, \dx^2 + \dx^3 - 2x \,\dx^4$ is second order at every point, since the lowest exponent of $\dx$ appearing in all its terms is 2 (the exponents of $x$ don't matter).
Similarly, $xy\,\dx\,\dy^2 + y \dx^4$ is third order, since $\dx\,\dy^2$ has total degree 3 and $\dx^4$ has total degree 4.
The ``coefficients'' can be arbitrary functions of $\pt{x}$ as well; for instance, $e^x \dx^2$ is second order.

\begin{rmk}
  If a form is $n\th$ order, then it is also $m\th$ order for any $m<n$.
  Thus, any second order form is also first order and zeroth order, and so on.
  We usually emphasize the greatest order that a form has; e.g.\ we almost always care most that $\dx^2$ is second order, even though it is also first and zeroth order.
\end{rmk}

\begin{eg}
  A differential form can have a higher order at some points than others.
  For instance, the form $x \,\dx + \dx^2$ is first-order everywhere, but at the point $x=0$ it becomes $0\, dx + \dx^2 = \dx^2$, which is second order.
\end{eg}

\begin{adv}
  The notion we've called ``$n\th$ order'' actually ought to be called ``smaller than $(n-1)\st$ order''.
  For forms ``whose order is an integer'', such as polynomials, there is no real difference between the two.
  However, a form such as $\dx^{3/2}$ is ``second-order'' by our definition, but really ought to be called ``$(3/2)\th$ order''.
\end{adv}


\section{Differentials}
\label{sec:differentials}

In one-variable calculus, you may have encountered the differential of a function.
Namely, if $f$ is a function of one variable $x$, then its differential is
\begin{equation}
  \df = f'(x) \, \dx\label{eq:onevariable-differential}
\end{equation}
where $f'$ is the \emph{derivative} of $f$.
This can be interpreted in terms of the graph of the function $f$\dots

\Cref{eq:onevariable-differential} defines the \emph{differential} of $f$ in terms of the \emph{derivative} of $f$.
However, in multivariable calculus, it is more appropriate to do things in the other order, defining the differential first.
Linear approximation\dots

\begin{defn}
  If $f$ is a function of a point $\pt{x}$, then its \textbf{differential} is a linear differential 1-form $\df$ such that
  \[ f(\pt{x} + \dd\pt{x}) - f(\pt{x}) - \df \]
  is second order at $\pt{x}$.
  If such a form $\df$ exists, we say that $f$ is \textbf{differentiable} at $\pt{x}$.
\end{defn}

\begin{eg}
  Let $f(x) = x^2$, an ordinary one-variable function.
  Then
  \begin{align*}
    f(x + \dx) - f(x) &= (x+\dx)^2 - x^2\\
    &= x^2 + 2 x \, \dx + \dx^2 - x^2\\
    &= 2x \, \dx + \dx ^2.
  \end{align*}
  What linear form $\dd f$ can we subtract from this to make it second order?
  Recalling the rule for orders of polynomials, we may think of subtracting $2x \, \dx$, leaving the second-order term $\dx^2$:
  \[ f(x + \dx) - f(x) - 2x \, \dx \;=\; \dx^2. \]
  Thus, we have $\dd(x^2) = 2 x \, \dx$.
  Of course, this is the same result that we would have gotten from \cref{eq:onevariable-differential}.
\end{eg}

\begin{eg}
  Let $f(x,y) = x^2 + 2y^2 - xy$.
  Then
  \begin{align*}
    f(x+\dx,y+\dy) - f(x,y)
    &= (x+\dx)^2 + 2(y+\dy)^2 - (x+\dx)(y+\dy) - x^2 - 2y^2 + xy\\
    &= x^2 + 2 x \, \dx + \dx^2 + 2y^2 + 4y\,\dy + 2\dy^2\\
    & \hspace{2cm} - x^2 - x \, \dy - y \, dx - \dx \dy - x^2 - 2y^2 + xy\\
    &= 2x\,\dx + 4y\,\dy - x\,\dy - y\,\dx + \dx^2 + 2\dy^2 - \dx\,\dy\\
    &= (2x-y)\,\,dx + (4y-x)\,\dy + (\dx^2 + 2\dy^2 - \dx\,\dy)
  \end{align*}
  In the last line we have separated this into a linear form plus one of second order.
  Thus, we have
  \[ \dd(x^2 + 2y^2 - xy) = (2x-y)\,\dx + (4y-x)\,\dy .\]
\end{eg}

\begin{eg}
  Consider $f(x) = \sin x$.
  Using the sum identity for sine, we have
  \begin{align*}
    \sin(x+\dx) - \sin (x)
    &= \sin x \cos \dx + \sin \dx \cos x - \sin x\\
    &= \cos x \sin \dx + (\sin x) (\cos \dx - 1).
  \end{align*}
  The usual way to proceed from here is to recall the limits
  \[ \lim_{h\to 0} \frac{\sin h}{h} = 1 \qquad\text{and}\qquad
  \lim_{h\to 0} \frac{\cos h - 1}{h} = 0 \]
  The second one implies that
  \[ \lim_{h\to 0} \frac{\cos (h\,\dx) - 1}{h} = 0 \]
  and therefore the form $\cos \dx - 1$ is second-order.
  Similarly, the first one implies that
  \[ \lim_{h\to 0} \frac{\sin (h\, \dx) - h \, \dx}{h} = 0 \]
  and therefore the form $\sin \dx - \dx$ is second-order.
  The ordinary functions $\cos x$ and $\sin x$ are zeroth order, so by the rules for orders, multiplying by them doesn't change the order.
  Thus, we can write
  \begin{align*}
    \sin(x+\dx) - \sin (x)
    &= \cos x \sin \dx + (\sin x) (\cos \dx - 1)\\
    &= (\cos x )(\dx  + \sin \dx - \dx) + (\sin x) (\cos \dx - 1)\\
    &= \cos x \,\dx + (\cos x) (\sin \dx - \dx) + (\sin x) (\cos \dx - 1)
  \end{align*}
  which is written as the linear form $\cos x \,\dx$ plus a second-order one.
  Thus, $\dd(\sin x) = \cos x \,\dx$.

  Another, perhaps more intuitive, way to proceed is to recall the power series expansions
  \begin{align*}
    \sin x &= x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots\\[2pt]
    \cos x &= 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots
  \end{align*}
  Therefore, we have
  \begin{align*}
    \sin \dx - \dx &= - \frac{\dx^3}{3!} + \frac{\dx^5}{5!} - \cdots\\[2pt]
    \cos \dx - 1 &= - \frac{\dx^2}{2!} + \frac{\dx^4}{4!} - \cdots
  \end{align*}
  so the rules for orders of polynomials say that the first is third-order (hence also second-order) and the second is second-order.
  This does require knowing that the rules for orders of polynomials also apply to power series, but this is true.
  (A deeper problem is that when calculating the power series expansions of sine and cosine in one-variable calculus, you probably used the fact that you already knew their derivatives.)
\end{eg}

A convenient way to work with differentials is to introduce the notion of ``approximation to first order''.

\begin{defn}
  We say that two differential forms $\omega$ and $\eta$ are \textbf{equal to $n\th$ order} if their difference $\omega-\eta$ is $(n+1)\st$ order.
  In this case we write
  \[\omega\apx{n} \eta.\]
\end{defn}

For example, we have $x\,\dx + \dx^2 \apx1 x\,\dx - e^x \dx^2$, since their difference is
\[ (x\,\dx + \dx^2) - (x\,\dx - e^x \dx^2) = (1+e^x)\dx^2 \]
which is second order.

The relation $\apx{n}$ behaves roughly like equality.
For instance, we can add or subtract the same differential form from both sides.
We can also multiply both sides by any continuous differential form, since multiplying by a zeroth order form doesn't change the order.
Finally, we can of course discard any terms of greater than $n\th$ order from an $n\th$-order approximate equality.

Now we can equivalently state the definition of a differential: $\df$ is a linear differential 1-form such that
\[ f(x+\dx) \apx1 f(x) + \df, \]
if such exists.
Our previous calculations of differentials can all be written in this way.
For instance,
\begin{align*}
  (x+\dx)^2 &= x^2 + 2 x\,\dx + \dx^2\\
  &\apx1 x^2 + 2 x\,\dx
\end{align*}
since $\dx^2$ is second order.
Therefore, $\dd(x^2) = 2x\,\dx$.

We can also deduce all the usual derivative rules, written in terms of differentials.
For instance, given functions $f$ and $g$, consider their sum $f+g$.
\begin{align*}
  f(x+\dx) + g(x+\dx)
  &\apx1 f(x) + \df + g(x) + \dg\\
  &= \big[f(x) + g(x)\big] + \big[ \df + \df \big]
\end{align*}
Thus, we have
\[ \dd(f+g) = \df + \dg. \]
Similarly, for the product rule, we compute
\begin{align*}
  f(x+\dx) \, g(x+\dx)
  &\apx1 \big(f(x)+\df\big)\big(g(x) + \dg \big)\\
  &= f(x) g(x) + f(x) \,\dg + g(x) \,\df + \df\,\dg\\
  &\apx1 f(x) g(x) + f(x) \,\dg + g(x) \,\df
\end{align*}
since $\df\,\dg$ is a product of two first-order forms, hence second-order.
Thus,
\[ \dd(f\,g) = f\,\dg + g\,\df.\]
% TODO: Chain rule

Importantly, these same rules apply to functions of more than one variable.

\begin{eg}
  If $f(x,y) = x^2y + xy^2$, then we can use the sum and product rules to obtain
  \begin{align*}
    \dd(x^2y + xy^2) &= \dd(x^2y) + \dd(xy^2)\\
    &= x^2\,\dy + y \,\dd(x^2) + x \,\dd(y^2) + y^2\,\dx\\
    &= x^2\,\dy + y \,(2x\,\dx) + x\, (2y\,\dy) + y^2\,\dx\\
    &= (2xy + y^2)\,\dx + (x^2+2xy)\,\dy
  \end{align*}
\end{eg}

\section{Derivatives}
\label{sec:derivatives}

We can now define the \emph{derivative} in terms of the \emph{differential}.
Note that in one dimension, a linear differential 1-form must be of the form
\[ g(x) \,\dx \]
for some function $g$.
In particular, if $f$ is a differentiable function, then $\dd f = g(x) \, \dx$ for some function $g$, which we call the \emph{derivative} of $f$ and denote by $f'$.
In other words,
\[ f'(x) = \frac{\dd f}{\dx}, \]
which is a notation that you have probably seen before.
The point is that now, we have given separate meanings to $\dx$ and $\dd f$, and \emph{defined} $f'(x)$ to be their quotient.


\end{document}